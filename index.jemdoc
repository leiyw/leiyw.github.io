# jemdoc: nofooter
==Yunwen Lei 

~~~
{}{img_left}{Lei.jpg}{Yunwen Lei}
PhD,\n [https://www.math.hkbu.edu.hk/ Department of Mathematics], \n [https://www.hkbu.edu.hk/ Hong Kong Baptist University]\n
Kowloon Tong\n
Kowloon\n
Hong Kong\n
E-mail: /yunwen/ \[@\] hkbu.edu.hk\n
~~~

== About Me
I am an Assistant Professor at the Department of Mathematics, Hong Kong Baptist University. Previously, I was a Lecturer at School of Computer Science, University of Birmingham, a [https://www.humboldt-foundation.de/en/connect/explore-the-humboldt-network/singleview?tx_rsmavhsolr_solrviewhumboldtians%5BpPersonId%5D=1203562&cHash=649af7ffa9150b9ad53a5445e4e369b2 Humboldt Research Fellow] at University of Kaiserslautern, a Research Assistant Professor at Southern University of Science and Technology, and a Postdoctoral Research Fellow at City University of Hong Kong. I obtained my PhD degree in Computer Science from Wuhan University, and my Bachelor degree in Mathematics from Hunan University. 



== Research
My research interests lie in the areas of machine learning and learning theory, with emphasis on the following topics: online learning, deep learning, optimization and extreme classification. In particular, I am interested in developing and analyzing scalable optimization methods for large-scale learning problems.

=== Selected Journal Publications 
. T. Hu and Y. Lei. \"[paper/21-0983.pdf Early Stopping for Iterative Regularization with General Loss Functions]\". Journal of Machine Learning Research, 23:1--36, 2022.
. P. Wang, Y. Lei, Y. Ying and H. Zhang. \"[paper/ACHA2021.pdf Differentially Private SGD with Non-smooth Losses]\". Applied Computational and Harmonic Analysis, 56:306-336, 2022.
. Y. Lei and K. Tang. \"[paper/TPAMI2021.pdf Learning Rates for Stochastic Gradient Descent with Nonconvex Objectives]\". IEEE Transactions on Pattern Analysis and Machine Intelligence, 43(12): 4505--4511, 2021.
. Y. Lei and Y. Ying. \"[paper/19-418.pdf Stochastic Proximal AUC Maximization]\". Journal of Machine Learning Research, 22(61):1-45, 2021. 
. Y. Lei, T. Hu and K. Tang. \"[paper/19-716.pdf Generalization Performance of Multi-pass Stochastic Gradient Descent with Convex Loss Functions]\". Journal of Machine Learning Research, 22(25):1−41, 2021.
. Y. Lei, T. Hu, G. Li and K. Tang. \"[paper/TNNLS2020.pdf Stochastic Gradient Descent for Nonconvex Learning without Bounded Gradient Assumptions]\". IEEE Transactions on Neural Networks and Learning Systems, 31(10):4394-4400, 2020.
. Y. Lei and D.-X. Zhou. \"[paper/ACHA2020.pdf Convergence of Online Mirror Descent]\". Applied Computational and Harmonic Analysis, 48(1):343-373, 2020. [slide/ACHA2020.pdf Talk Slides]
. S.-B. Lin, Y. Lei and D.-X. Zhou. \"[paper/18-063.pdf Boosted Kernel Ridge Regression: Optimal Learning Rates and Early Stopping]\". Journal of Machine Learning Research, 20(46):1-36, 2019.
. Y. Lei, U. Dogan, D.-X. Zhou and M. Kloft. \"[paper/TIT2019.pdf Data-dependent Generalization Bounds for Multi-class Classification]\". IEEE Transactions on Information Theory, 65(5): 2995-3021, 2019. [slide/TIT2019.pdf Talk Slides]
. Y. Lei and D.-X. Zhou. \"[paper/JFAA2019.pdf Analysis of Singular Value Thresholding Algorithm for Matrix Completion]\". Journal of Fourier Analysis and Applications, 25 (6):2957-2972, 2019.
. N. Yousefi, Y. Lei, M. Kloft, M. Mollaghasemi and G. Anagnostopoulos. \"[paper/17-144.pdf Local Rademacher Complexity-based Learning Guarantees for Multi-task Learning]\". Journal of Machine Learning Research, 19(38):1-47, 2018.
. Y. Lei, L. Shi and Z.-C. Guo. \"[paper/17-457.pdf Convergence of Unregularized Online Learning Algorithms]\". Journal of Machine Learning Research, 18(171):1-33, 2018.
. Y. Lei and D.-X. Zhou. \"[paper/SIAM2018.pdf Learning Theory of Randomized Sparse Kaczmarz Method]\". SIAM Journal on Imaging Sciences, 11(1):547-574, 2018.
. J. Lin, Y. Lei, B. Zhang and D.-X. Zhou. \"[paper/Pairwise2016.pdf Online Pairwise Learning Algorithms with Convex Loss Functions]\". Information Sciences, 406-407(9):57-70, 2017.
. Y. Lei and D.-X. Zhou. \"[paper/Neco2016.pdf Analysis of Online Composite Mirror Descent Algorithm]\". Neural Computation, 29(3):825-860, 2017.
. Y. Lei and Y. Ying. \"[paper/AA2016.pdf Generalization Analysis of Multi-modal Metric Learning]\". Analysis and Applications, 14(4): 503-521, 2016.
. Y. Lei, L. Ding and W. Zhang. \"[paper/RBF2015.pdf Generalization Performance of Radial Basis Function Networks]\". IEEE Transactions on Neural Networks and Learning Systems, 26(3):551-564, 2015.


=== Selected Conference Publications 
. S. Fu, Y. Lei, Q. Cao, X. Tian and D. Tao. \"[paper/ICLR2023.pdf Sharper Bounds for Uniformly Stable Algorithms with Stationary mixing Process]\". In International Conference on Learning Representations, (to appear) 2023.
. Y. Lei, R. Jin and Y. Ying. \"[paper/NeurIPS2022a.pdf Stability and Generalization Analysis of Gradient Methods for Shallow Neural Networks]\". In Advances in Neural Information Processing Systems, (to appear) 2022.
. P. Wang, Y. Lei, Y. Ying and D.-X. Zhou. \"[paper/NeurIPS2022b.pdf Stability and Generalization for Markov Chain Stochastic Gradient Methods]\". In Advances in Neural Information Processing Systems, (to appear) 2022.
. M. Liu, Z. Zhang, Y. Lei and C. Liao. \"[paper/NeurIPS2022c.pdf A Communication-Efficient Distributed Gradient Clipping Algorithm for Training Deep Neural Networks]\". In Advances in Neural Information Processing Systems, (to appear) 2022.
. W. Mustafa, Y. Lei and M. Kloft. \"[paper/ICML2022.pdf On the Generalization Analysis of Adversarial Learning]\". In International Conference on Machine Learning, pages 16174--16196, 2022.
. Z. Huang, Y. Lei and A. Kaban. \"[paper/ECML2022.pdf Noise-efficient Learning of Differentially Private Partitioning Machine Ensembles]\". In European Conference on Machine Learning, (to appear) 2022.
. Z. Yang, S. Hu, Y. Lei, K. Varshney, S. Lyu, Y. Ying. \"[paper/UAI2022.pdf Differentially Private SGDA for Minimax Problems]\". In Uncertainty in Artificial Intelligence, (to appear) 2022.
. Y. Lei, M. Liu and Y. Ying. \"[paper/NeurIPS2021a.pdf Generalization Guarantee of SGD for Pairwise Learning]\". In Advances in Neural Information Processing Systems, pages 21216-21228, 2021.  [slide/NeurIPS2021a.pdf Talk Slides]
. Z. Yang, Y. Lei, P. Wang, T. Yang and Y. Ying. \"[paper/NeurIPS2021b.pdf Simple Stochastic and Online Gradient Descent Algorithms for Pairwise Learning]\". In Advances in Neural Information Processing Systems, pages 20160-20171, 2021.
. A. Ledent, R. Alves, Y. Lei and M. Kloft. \"[paper/NeurIPS2021c.pdf Fine-grained Generalization Analysis of Inductive Matrix Completion]\". In Advances in Neural Information Processing Systems, pages 25540--25552, 2021. 
. Y. Lei, Z. Yang, T. Yang and Y. Ying. \"[paper/ICML2021.pdf Stability and Generalization of Stochastic Gradient Methods for Minimax Problems]\". In International Conference on Machine Learning, pages 6175-6186, 2021. (+Long Presentation+ acceptance rate: 3%) [slide/ICML2021.pdf Talk Slides]
. Y. Lei and Y. Ying. \"[paper/ICLR2021.pdf Sharper Generalization Bounds for Learning with Gradient-dominated Objective Functions]\". In International Conference on Learning Representations, 2021. [slide/ICLR2021.pdf Talk Slides]
. Z. Yang, Y. Lei, S. Lyu and Y. Ying. \"[paper/yang21c.pdf Stability and Differential Privacy of Stochastic Gradient Descent for Pairwise Learning with Non-Smooth Loss]\". In International Conference on Artificial Intelligence and Statistics, pages 2026-2034, 2021.
. Y. Lei, A. Ledent and M. Kloft. \"[paper/NeurIPS2020.pdf Sharper Generalization Bounds for Pairwise Learning]\". In Advances in Neural Information Processing Systems, pages 21236-21246, 2020. [slide/NeurIPS2020.pdf Talk Slides]
. Y. Lei and Y. Ying. \"[paper/ICML2020.pdf Fine-Grained Analysis of Stability and Generalization for Stochastic Gradient Descent]\". In International Conference on Machine Learning, pages 5809-5819, 2020. [slide/ICML2020.pdf Talk Slides]
. Y. Lei, P. Yang, K. Tang and D.-X. Zhou. \"[paper/NeurIPS2019.pdf Optimal Stochastic and Online Learning with Individual Iterates]\". In Advances in Neural Information Processing Systems, pages 5416-5426, 2019.  (+Spotlight+ acceptance rate: 3%) [slide/NeurIPS2019.pdf Talk Slides]
. Y. Lei and K. Tang. \"[paper/NeurIPS2018.pdf Stochastic Composite Mirror Descent: Optimal Bounds with High Probabilities]\". In Advances in Neural Information Processing Systems, pages 1526-1536, 2018.
. Y. Lei, S.-B. Lin and K. Tang. \"[paper/IJCAI2018.pdf Generalization Bounds for Regularized Pairwise Learning]\". In International Joint Conference on Artificial Intelligence, pages 2376-2382, 2018.
. Y. Lei, A. Binder, U. Dogan and M. Kloft. \"[paper/ACML2016.pdf Localized Multiple Kernel Learning-A Convex Approach]\". In Asian Conference on Machine Learning, 63:81-96, 2016.
. Y. Lei, U. Dogan, A. Binder and M. Kloft. \"[paper/NIPS2015.pdf Multi-class SVMs: From Tighter Data-Dependent Generalization Bounds to Novel Algorithms]\". In Advances in Neural Information Processing Systems, pages 2026-2034, 2015.


== Teaching
- Current Topics in Artificial Intelligence and Machine Learning, University of Birmingham, Spring 2021 (with Jonathan Rowe and Peter Tino).
- Artificial Intelligence, University of Birmingham, Spring 2021 (with Shan He, Miqing Li and Kashif Rajpoot).
- Neural Computation, University of Birmingham, Autumn 2020 (with Per Kristian Lehre, Jinming Duan and Shan He).
- Machine Learning 3: Mathematics of ML, TU Kaiserslautern, Winter 2019/2020 (with Marius Kloft).
- Intelligent Data Analysis (Lab course), SUSTech, Spring 2019.
- Artificial Intelligence (Lab course), SUSTech, Autumn 2018.


== Referee Experience
: {Journal} 
[https://www.worldscientific.com/worldscinet/aa AA], 
[https://www.journals.elsevier.com/applied-and-computational-harmonic-analysis ACHA], 
[https://www.journals.elsevier.com/artificial-intelligence AIJ], 
[https://www.journals.elsevier.com/big-data-research BDR], 
[https://www.aimspress.com/journal/era ERA],
[https://www.tandfonline.com/toc/goms20/current GOMS],
[https://www.sciencedirect.com/journal/information-sciences INS],
[https://www.journals.elsevier.com/journal-of-approximation-theory JAT], 
[https://www.journals.elsevier.com/journal-of-computational-mathematics-and-data-science JCMDS],
[https://www.journals.elsevier.com/journal-of-complexity JoC], 
[https://www.comsoc.org/publications/journals/ieee-jsac/cfp/machine-learning-communications-and-networks JSAC],
[https://www.jmlr.org/ JMLR], 
[https://onlinelibrary.wiley.com/journal/19321872 SAM],
[https://www.siam.org/publications/journals/siam-journal-on-matrix-analysis-and-applications-simax SIMAX],
[https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=18 TIT], 
[https://dl.acm.org/journal/tkdd TKDD],
[https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=69 TKDE],
[https://www.jmlr.org/tmlr/ TMLR],
[https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34 TPAMI],
[https://signalprocessingsociety.org/publications-resources/ieee-transactions-signal-processing/about-ieee-transactions-signal-processing TSP], 
[https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385 TNNLS], 
[https://www.aimsciences.org/journal/A0000-0001 MFC], 
[https://www.springer.com/journal/10994 MLJ], 
[https://www.journals.elsevier.com/neurocomputing NEUCOM],
[https://www.journals.elsevier.com/neural-networks NEUNET],
[https://www.mitpressjournals.org/loi/neco NEURCOMP]


: {Conference} AAAI (2019-2022), ACML (2019--2022), AISTATS (2016--2023), COLT (2018), ECML (2021, 2022), ICLR (2018--2023), ICML (2018--2023), IJCAI (2019--2023), NeurIPS (2016--2022) 